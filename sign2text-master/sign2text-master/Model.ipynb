{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1GHMogLoQw_jn27p3rqwidgVd2QVlk0yp",
      "authorship_tag": "ABX9TyOYTrQkNzYWC+EGcS0bXDzR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VedangJotaniya/CP441_Project_Repo/blob/gh-pages/sign2text-master/sign2text-master/Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wx_U-fFjogWD",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jZqd4w0olU-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "from glob import glob\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHx290eRogLh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def square_pad(img, padding_color=[0, 0, 0]):\n",
        "    \"\"\"Add margins to image to make it square keeping largest original dimension\n",
        "    Parameters\n",
        "    ----------\n",
        "    img: numpy.ndarray\n",
        "        Image to be processed\n",
        "    padding_color: list\n",
        "        Define background colour to pad image; preserves RGB/BGR colour channel order of img\n",
        "    Returns\n",
        "    -------\n",
        "    padded_img: np.ndarray\n",
        "        Image padded to a square shape\n",
        "    \"\"\"\n",
        "    height = img.shape[0]\n",
        "    width = img.shape[1]\n",
        "    # find difference between longest side\n",
        "    diff = np.abs(width - height)\n",
        "    # amount of padding = half the diff between width and height\n",
        "    pad_diff = diff // 2\n",
        "\n",
        "    if height > width:\n",
        "        # letter is longer than it is wide\n",
        "        pad_top = 0\n",
        "        pad_bottom = 0\n",
        "        pad_left = pad_diff\n",
        "        pad_right = pad_diff\n",
        "        padded_img = cv2.copyMakeBorder(img,\n",
        "                                        top=pad_top,\n",
        "                                        bottom=pad_bottom,\n",
        "                                        left=pad_left,\n",
        "                                        right=pad_right,\n",
        "                                        borderType=cv2.BORDER_CONSTANT,\n",
        "                                        value=padding_color)\n",
        "    elif width > height:\n",
        "        # image is wide\n",
        "        pad_top = pad_diff\n",
        "        pad_bottom = pad_diff\n",
        "        pad_left = 0\n",
        "        pad_right = 0\n",
        "        padded_img = cv2.copyMakeBorder(img,\n",
        "                                        top=pad_top,\n",
        "                                        bottom=pad_bottom,\n",
        "                                        left=pad_left,\n",
        "                                        right=pad_right,\n",
        "                                        borderType=cv2.BORDER_CONSTANT,\n",
        "                                        value=padding_color)\n",
        "    elif width == height:\n",
        "        padded_img = img.copy()\n",
        "\n",
        "    return padded_img\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_gTkMPuo3Wy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_for_vgg(img, size=224, color=True):\n",
        "    \"\"\"Image pre-processing for VGG16 network\n",
        "    Parameters\n",
        "    ----------\n",
        "    img: numpy.ndarray\n",
        "        Image to be processed\n",
        "    size: int\n",
        "        Size to which image is re-sized (square of shape: size x size)\n",
        "    color: bool\n",
        "        If the image is colour (BGR colour channels), then it is zero-centred by mean pixel\n",
        "    Returns\n",
        "    -------\n",
        "    x: np.ndarray\n",
        "        Pre-processed image ready to feed into VGG16 network; re-shaped to (1, size, size, 3)\n",
        "    \"\"\"\n",
        "    img = cv2.resize(img, (size, size))\n",
        "    x = np.array(img, dtype=float)\n",
        "    x_fake_batch = x.reshape(1, *x.shape)\n",
        "    x = x_fake_batch\n",
        "    if color:\n",
        "        # Zero-center by mean pixel\n",
        "        x[:, :, :, 2] -= 123.68\n",
        "        x[:, :, :, 1] -= 116.779\n",
        "        x[:, :, :, 0] -= 103.939 \n",
        "    return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIVp43KKo3Lk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZAVYTU_o267",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAECRtgTof1g",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MA_R1UNcofr2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUf5B1VOofgs",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBQdNmJc8Tt5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "from tensorflow.keras.applications.mobilenet import MobileNet\n",
        "\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout, Input\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "\n",
        "import argparse\n",
        "\n",
        "# Map model names to classes\n",
        "MODELS = {\n",
        "    \"vgg16\": VGG16,\n",
        "    \"inception\": InceptionV3,\n",
        "    \"xception\": Xception,\n",
        "    \"resnet\": ResNet50,\n",
        "    \"mobilenet\": MobileNet\n",
        "}\n",
        "\n",
        "# Define path to pre-trained classification block weights - this is\n",
        "vgg_weights_path = \"weights/snapshot_vgg_weights.hdf5\"\n",
        "res_weights_path = \"weights/snapshot_res_weights.hdf5\"\n",
        "mob_weights_path = \"weights/snapshot_mob_weights.hdf5\"\n",
        "\n",
        "def create_model(model, model_weights_path=None, top_model=True, color_mode=\"rgb\", input_shape=None):\n",
        "    \"\"\"Create custom model for transfer learning\n",
        "    Steps:\n",
        "    (i) load pre-trained NN architecture\n",
        "    (ii) (optional) add custom classification block of two fully connected layers\n",
        "    (iii) load pre-trained model weights, if available\n",
        "    Parameters\n",
        "    ----------\n",
        "    model: str\n",
        "        choose which pre-trained Keras deep learning model to use for the 'bottom' layers of the custom model\n",
        "    model_weights_path: str\n",
        "        optional path to weights for classification block; otherwise, pre-trained weights will be loaded\n",
        "    top_model: bool\n",
        "        whether to include custom classification block, or to load model 'without top' to extract features\n",
        "    color_mode: str\n",
        "        whether the image is gray scale or RGB; this will determine number of channels of model input layer\n",
        "    Returns\n",
        "    -------\n",
        "    my_model: keras.model\n",
        "        Model utilised for prediction or training\n",
        "    \"\"\"\n",
        "\n",
        "    # ensure a valid model name was supplied\n",
        "    if model not in MODELS.keys():\n",
        "        raise AssertionError(\"The model parameter must be a key in the `MODELS` dictionary\")\n",
        "\n",
        "    # gray scale or color\n",
        "    if color_mode == \"grayscale\":\n",
        "        num_channels = 1\n",
        "    else:\n",
        "        num_channels = 3\n",
        "\n",
        "    # Create pre-trained model for feature extraction, without classification block\n",
        "    print(\"[INFO] loading %s...\" % (model,))\n",
        "    model = MODELS[model](include_top=False,\n",
        "                          input_shape=(224, 224, 3))\n",
        "\n",
        "    # For transfer learning\n",
        "    if top_model:\n",
        "        # Create classification block\n",
        "        top_model = Sequential()\n",
        "        top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
        "        top_model.add(Dense(256, activation='relu'))\n",
        "        top_model.add(Dense(26, activation='softmax'))\n",
        "\n",
        "        # Load weights for classification block\n",
        "        print(\"[INFO] loading model weights.\")\n",
        "        if model_weights_path is not None:\n",
        "            # user-supplied weights\n",
        "            print(model_weights_path)\n",
        "            top_model.load_weights(model_weights_path)\n",
        "        elif model == \"vgg16\":\n",
        "            # pre-trained weights for transfer learning with VGG16\n",
        "            top_model.load_weights(vgg_weights_path)\n",
        "        elif model == \"resnet\":\n",
        "            # pre-trained weights for transfer learning with ResNet50\n",
        "            print(\"ResNet50 pre-trained weights are not available yet, please use VGG16 for now!\")\n",
        "            top_model.load_weights(res_weights_path)\n",
        "        elif model == \"mobnet\":\n",
        "            # pre-trained weights for transfer learning with ResNet50\n",
        "            print(\"ResNet50 pre-trained weights are not available yet, please use VGG16 for now!\")\n",
        "            top_model.load_weights(mob_weights_path)\n",
        "\n",
        "        # Join pre-loaded model + classification block\n",
        "        print(\"[INFO] creating model.\")\n",
        "        my_model = Model(inputs=model.input,\n",
        "                         outputs=top_model(model.output))\n",
        "        return my_model\n",
        "    else:\n",
        "        return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jM-LWxe4gwPq",
        "colab_type": "text"
      },
      "source": [
        "Instantiate the model by calling given upper function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6hVEmMSgvkk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_model = create_model(model=args[\"model\"],\n",
        "                        model_weights_path=args[\"weights\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqu5d_RRoeCl",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFiktPOvMGs-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = 313\n",
        "    y = 82\n",
        "    w = 451\n",
        "    h = 568\n",
        "    cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 255, 0), 3)\n",
        "\n",
        "    # Crop + process captured frame\n",
        "    hand = frame[83:650, 314:764]\n",
        "    hand = square_pad(hand)\n",
        "    hand = preprocess_for_vgg(hand)\n",
        "\n",
        "    # Make prediction\n",
        "    my_predict = my_model.predict(hand,\n",
        "                                  batch_size=1,\n",
        "                                  verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vf2xbzNegxOB",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBZoWeQbMHJs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}